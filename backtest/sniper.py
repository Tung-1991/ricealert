# /root/ricealert/backtest/backtest_sniper.py
# PHI√äN B·∫¢N 5.3 - STRATEGY LAB REFINED & CONCISE REPORTING

import os
import sys
import pandas as pd
import joblib
import warnings
import json
from datetime import datetime
from typing import Dict, List, Tuple
import numpy as np
from collections import deque

# --- Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n & Import ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)
warnings.filterwarnings("ignore", category=UserWarning)

from trainer import get_full_price_history, add_features
from trade_advisor import get_advisor_decision, FULL_CONFIG

# ==============================================================================
# ================= üî¨ PH√íNG TH√ç NGHI·ªÜM CHI·∫æN L∆Ø·ª¢C üî¨ =====================
# ==============================================================================
STRATEGY_CONFIGS = {
    # ‚öôÔ∏è M·ªöI: AI v·ªõi r·ªßi ro th·ª±c t·∫ø - SL 3%, RR 2
    "AI_ThucTe_3SL_2RR": {
        "NOTES": "AI G·ªëc - Th·ª≠ nghi·ªám SL 3% v√† RR 2.0 ƒë·ªÉ c√¢n b·∫±ng L·ª£i nhu·∫≠n/R·ªßi ro.",
        "WEIGHTS_OVERRIDE": {'tech': 0.0, 'ai': 1.0, 'context': 0.0},
        "ENTRY_SCORE_THRESHOLD": 6.5,  # Ng∆∞·ª°ng v√†o l·ªánh h·ª£p l√Ω
        "RR_RATIO": 2.0,               # T·ª∑ l·ªá RR ti√™u chu·∫©n
        "SL_PERCENT": 0.03,            # << SL 3%, m·ªôt con s·ªë th·ª±c t·∫ø h∆°n nhi·ªÅu
        "SCORE_RANGE_OVERRIDE": 7
    },

    # ‚öôÔ∏è M·ªöI: AI v·ªõi r·ªßi ro v·ª´a ph·∫£i - SL 5%, RR 2
    "AI_ThucTe_5SL_2RR": {
        "NOTES": "AI G·ªëc - Cho ph√©p bi·∫øn ƒë·ªông nhi·ªÅu h∆°n v·ªõi SL 5%.",
        "WEIGHTS_OVERRIDE": {'tech': 0.0, 'ai': 1.0, 'context': 0.0},
        "ENTRY_SCORE_THRESHOLD": 6.5,
        "RR_RATIO": 2.0,
        "SL_PERCENT": 0.05,            # << SL 5%, ph√π h·ª£p cho swing trade ng·∫Øn
        "SCORE_RANGE_OVERRIDE": 7
    },

    # ‚öôÔ∏è M·ªöI: AI v·ªõi r·ªßi ro cao h∆°n - SL 8%, RR 1.8
    "AI_ThucTe_8SL_1.8RR": {
        "NOTES": "AI G·ªëc - SL r·ªông (8%) ƒë·ªÉ b·∫Øt c√°c con s√≥ng l·ªõn, RR gi·∫£m nh·∫π.",
        "WEIGHTS_OVERRIDE": {'tech': 0.0, 'ai': 1.0, 'context': 0.0},
        "ENTRY_SCORE_THRESHOLD": 6.0, # Gi·∫£m ng∆∞·ª°ng ƒë·ªÉ b·∫Øt nhi·ªÅu t√≠n hi·ªáu h∆°n
        "RR_RATIO": 1.8,
        "SL_PERCENT": 0.08,            # << SL 8%, ch·∫•p nh·∫≠n r·ªßi ro cao h∆°n
        "SCORE_RANGE_OVERRIDE": 7
    },
    
    # Gi·ªØ l·∫°i chi·∫øn l∆∞·ª£c AI 20% SL ƒë·ªÉ so s√°nh
    "AI_Goc_20SL": {
        "NOTES": "Chi·∫øn l∆∞·ª£c AI g·ªëc v·ªõi SL 20% ƒë·ªÉ l√†m c∆° s·ªü so s√°nh.",
        "WEIGHTS_OVERRIDE": {'tech': 0.0, 'ai': 1.0, 'context': 0.0},
        "ENTRY_SCORE_THRESHOLD": 7,
        "RR_RATIO": 1,
        "SL_PERCENT": 0.2,
        "SCORE_RANGE_OVERRIDE": 8
    }
}
# --- C√°c h·∫±ng s·ªë Backtest ---
SYMBOLS_TO_TEST = ["ETHUSDT", "AVAXUSDT", "INJUSDT", "LINKUSDT", "SUIUSDT", "FETUSDT", "TAOUSDT"]
INTERVALS_TO_TEST = ["1h", "4h", "1d"]
TOTAL_DAYS_TO_TEST = 90
INITIAL_CAPITAL = 10000.0
TRADE_AMOUNT_PERCENT = 0.1
COMMISSION_RATE = 0.0004

# --- ƒê∆∞·ªùng d·∫´n ---
CACHE_DIR = os.path.join(current_dir, "data_cache")
DATA_DIR = os.path.join(project_root, "data")
BACKTEST_RESULTS_DIR = os.path.join(current_dir, "backtest_results")
os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(BACKTEST_RESULTS_DIR, exist_ok=True)

# ==============================================================================
# C√ÅC H√ÄM T·∫¢I V√Ä CHU·∫®N B·ªä D·ªÆ LI·ªÜU
# ==============================================================================
def load_all_historical_data(symbols: List[str], intervals: List[str], days: int) -> Dict:
    print(f"\n[Backtest] T·∫£i d·ªØ li·ªáu gi√° cho {len(symbols)} symbols, {len(intervals)} intervals ({days} ng√†y)...")
    all_data = {}
    for symbol in symbols:
        all_data[symbol] = {}
        for interval in intervals + ['1d']: # Lu√¥n t·∫£i th√™m d·ªØ li·ªáu 1d
            try:
                if interval == '1h': limit_candles = days * 24 + 200
                elif interval == '4h': limit_candles = days * 6 + 200
                else: limit_candles = days + 200 # Cho khung 1d

                cache_file = os.path.join(CACHE_DIR, f"{symbol}-{interval}-{days}d.parquet")
                if os.path.exists(cache_file) and (datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))).days < 1:
                    df = pd.read_parquet(cache_file)
                else:
                    df = get_full_price_history(symbol, interval, limit_candles, 1000)
                    if not df.empty: df.to_parquet(cache_file)

                if not df.empty:
                    df_with_features = add_features(df)
                    all_data[symbol][interval] = df_with_features
            except Exception as e: print(f"L·ªói t·∫£i d·ªØ li·ªáu cho {symbol}-{interval}: {e}")
    print("‚úÖ Ho√†n th√†nh t·∫£i d·ªØ li·ªáu.")
    return all_data

def prepare_context_and_ai_data_for_backtest(all_data: Dict):
    print("\n[Backtest] Chu·∫©n b·ªã d·ªØ li·ªáu AI v√† Context cho to√†n b·ªô l·ªãch s·ª≠...")
    all_models = {}
    for symbol in SYMBOLS_TO_TEST:
        all_models[symbol] = {}
        for interval in INTERVALS_TO_TEST:
            try:
                clf_path = os.path.join(DATA_DIR, f"model_{symbol}_clf_{interval}.pkl")
                reg_path = os.path.join(DATA_DIR, f"model_{symbol}_reg_{interval}.pkl")
                meta_path = os.path.join(DATA_DIR, f"meta_{symbol}_{interval}.json")
                if os.path.exists(clf_path):
                    all_models[symbol][interval] = {"clf": joblib.load(clf_path), "reg": joblib.load(reg_path), "meta": json.load(open(meta_path, 'r'))}
            except Exception as e: print(f"L·ªói t·∫£i model AI cho {symbol}-{interval}: {e}")

    for symbol, symbol_data in all_data.items():
        for interval, df in symbol_data.items():
            if df.empty or interval == '1d': continue # Kh√¥ng c·∫ßn ch·∫°y AI cho 1d
            ai_model_info = all_models.get(symbol, {}).get(interval)
            if ai_model_info:
                model_features = ai_model_info['meta']['features']
                X_ai = df[model_features].reindex(columns=model_features, fill_value=0)
                probs_ai = ai_model_info['clf'].predict_proba(X_ai)
                classes_ai = ai_model_info['clf'].classes_.tolist()
                buy_idx = classes_ai.index(2) if 2 in classes_ai else -1
                sell_idx = classes_ai.index(0) if 0 in classes_ai else -1
                df['ai_prob_buy'] = probs_ai[:, buy_idx] * 100 if buy_idx != -1 else 50.0
                df['ai_prob_sell'] = probs_ai[:, sell_idx] * 100 if sell_idx != -1 else 0.0
                reg_preds = ai_model_info['reg'].predict(X_ai)
                df['ai_predicted_pct'] = (reg_preds * df['atr'] * 100) / (df['close'] + 1e-9)
            else:
                df['ai_prob_buy'], df['ai_prob_sell'], df['ai_predicted_pct'] = 50.0, 0.0, 0.0
            df['context_market_trend'], df['context_news_factor'] = "NEUTRAL", 0.0
    print("‚úÖ Ho√†n th√†nh chu·∫©n b·ªã d·ªØ li·ªáu AI v√† Context.")
    return all_data

# ==============================================================================
# H√ÄM BACKTEST CH√çNH
# ==============================================================================
def run_sniper_backtest(all_data: Dict, strategy_config: Dict):
    capital, trade_history = INITIAL_CAPITAL, []
    active_trades: Dict[Tuple[str, str], Dict] = {}
    debug_messages = deque(maxlen=3) # <-- THAY ƒê·ªîI: Gi·∫£m s·ªë d√≤ng debug

    # --- C·∫¢I TI·∫æN: Chu·∫©n b·ªã config m·ªôt l·∫ßn cho m·ªói chi·∫øn l∆∞·ª£c ---
    local_config = FULL_CONFIG.copy()
    if "SCORE_RANGE_OVERRIDE" in strategy_config:
        local_config["SCORE_RANGE"] = strategy_config["SCORE_RANGE_OVERRIDE"]

    all_indices = [df.index for symbol_data in all_data.values() for df in symbol_data.values() if not df.empty]
    if not all_indices: return [], capital, []

    master_index = pd.DatetimeIndex(pd.concat([s.to_series() for s in all_indices]).unique()).sort_values()
    end_date, start_date = master_index.max(), master_index.max() - pd.Timedelta(days=TOTAL_DAYS_TO_TEST)
    master_index = master_index[(master_index >= start_date) & (master_index <= end_date)]

    for timestamp in master_index:
        # Check close trades
        for (symbol, interval), trade in list(active_trades.items()):
            if symbol in all_data and interval in all_data[symbol] and timestamp in all_data[symbol][interval].index:
                current_price_data = all_data[symbol][interval].loc[timestamp]
                high, low = current_price_data['high'], current_price_data['low']
                status, exit_price = (("SL", trade['sl']) if low <= trade['sl'] else
                                      ("TP", trade['tp']) if high >= trade['tp'] else (None, None))
                if status:
                    pnl = (exit_price - trade['entry_price']) / trade['entry_price']
                    net_pnl_usd = (trade['amount_usd'] * pnl) - (trade['amount_usd'] * (1 + abs(pnl)) * COMMISSION_RATE)
                    capital += net_pnl_usd
                    trade.update({'exit_price': exit_price, 'exit_time': timestamp, 'pnl_percent': pnl * 100, 'pnl_usd': net_pnl_usd, 'status': status, 'final_capital': capital})
                    trade_history.append(trade)
                    del active_trades[(symbol, interval)]

        # Find new signals
        for symbol in SYMBOLS_TO_TEST:
            if any(key[0] == symbol for key in active_trades.keys()): continue
            for interval in INTERVALS_TO_TEST:
                if any(key[0] == symbol for key in active_trades.keys()): break
                df = all_data.get(symbol, {}).get(interval)
                if df is None or timestamp not in df.index: continue

                candle = df.loc[timestamp]
                indicators = candle.to_dict()
                indicators.update({"symbol": symbol, "interval": interval})

                # Chu·∫©n b·ªã RSI ƒëa khung th·ªùi gian
                for tf in ["1h", "4h", "1d"]:
                    df_tf = all_data.get(symbol, {}).get(tf)
                    indicators[f'rsi_{tf}'] = df_tf.loc[timestamp, 'rsi_14'] if df_tf is not None and timestamp in df_tf.index else indicators.get('rsi_14', 50)

                ai_data = {"prob_buy": candle.get('ai_prob_buy', 50.0), "prob_sell": candle.get('ai_prob_sell', 0.0), "pct": candle.get('ai_predicted_pct', 0.0)}
                context_data = {"market_trend": "NEUTRAL", "news_factor": 0.0}

                decision = get_advisor_decision(symbol, interval, indicators, local_config,
                                                ai_data_override=ai_data, context_override=context_data,
                                                weights_override=strategy_config["WEIGHTS_OVERRIDE"])

                debug_line = f"[DEBUG] {timestamp.strftime('%y-%m-%d %H:%M')} | {symbol}-{interval} | Score: {decision['final_score']:.2f} (SR: {local_config['SCORE_RANGE']})"
                debug_messages.append(debug_line)

                if decision['decision_type'] == "OPPORTUNITY_BUY" and decision['final_score'] >= strategy_config['ENTRY_SCORE_THRESHOLD']:
                    entry, amount = candle['close'], capital * TRADE_AMOUNT_PERCENT
                    if capital < amount: continue
                    sl = entry * (1 - strategy_config['SL_PERCENT'])
                    tp = entry * (1 + strategy_config['SL_PERCENT'] * strategy_config['RR_RATIO'])
                    capital -= (amount * COMMISSION_RATE)
                    active_trades[(symbol, interval)] = {'symbol': symbol, 'interval': interval, 'entry_price': entry, 'tp': tp, 'sl': sl, 'amount_usd': amount, 'status': "open", 'score': decision['final_score'], 'entry_time': timestamp}

    # Close remaining trades at the end
    for (symbol, interval), trade in list(active_trades.items()):
        if symbol in all_data and interval in all_data[symbol] and master_index.max() in all_data[symbol][interval].index:
            last_price = all_data[symbol][interval].loc[master_index.max()]['close']
            pnl = (last_price - trade['entry_price']) / trade['entry_price']
            net_pnl_usd = (trade['amount_usd'] * pnl) - (trade['amount_usd'] * (1 + abs(pnl)) * COMMISSION_RATE)
            capital += net_pnl_usd
            trade.update({'exit_price': last_price, 'exit_time': master_index.max(), 'pnl_percent': pnl * 100, 'pnl_usd': net_pnl_usd, 'status': "Closed (End)", 'final_capital': capital})
            trade_history.append(trade)

    return trade_history, capital, list(debug_messages)

# ==============================================================================
# B√ÅO C√ÅO K·∫æT QU·∫¢ N√ÇNG CAO
# ==============================================================================
def generate_backtest_report(strategy_name: str, config: Dict, trade_history: List[Dict], final_capital: float, debug_log: List[str]):
    print("\n\n" + "="*80)
    print(f"============== üìä B√ÅO C√ÅO CHI·∫æN L∆Ø·ª¢C: {strategy_name} üìä ==============")
    print(f"============== '{config['NOTES']}' ==============")
    print("="*80)

    if not trade_history:
        print("Kh√¥ng c√≥ giao d·ªãch n√†o ƒë∆∞·ª£c th·ª±c hi·ªán. H√£y th·ª≠ n·ªõi l·ªèng ng∆∞·ª°ng v√†o l·ªánh.")
        return

    df = pd.DataFrame(trade_history)
    df['entry_time'] = pd.to_datetime(df['entry_time'])
    df['exit_time'] = pd.to_datetime(df['exit_time'])
    df['holding_hours'] = (df['exit_time'] - df['entry_time']).dt.total_seconds() / 3600

    total_trades = len(df)
    winning_trades = df[df['pnl_usd'] > 0]
    losing_trades = df[df['pnl_usd'] <= 0]
    win_rate = (len(winning_trades) / total_trades * 100) if total_trades > 0 else 0
    total_pnl_usd = final_capital - INITIAL_CAPITAL
    net_profit_percent = (total_pnl_usd / INITIAL_CAPITAL * 100)
    avg_win_pnl = winning_trades['pnl_usd'].mean() if not winning_trades.empty else 0
    avg_loss_pnl = losing_trades['pnl_usd'].mean() if not losing_trades.empty else 0
    profit_factor = abs(winning_trades['pnl_usd'].sum() / losing_trades['pnl_usd'].sum()) if not losing_trades.empty and losing_trades['pnl_usd'].sum() != 0 else float('inf')

    df['cumulative_capital'] = df['final_capital']
    peak = df['cumulative_capital'].cummax()
    drawdown = (df['cumulative_capital'] - peak) / peak
    max_drawdown_percent = abs(drawdown.min() * 100) if not drawdown.empty else 0
    pnl_std = df['pnl_percent'].std()
    sharpe_ratio = (df['pnl_percent'].mean() / pnl_std) * np.sqrt(252 * (24 / (df['holding_hours'].mean() if df['holding_hours'].mean() > 0 else 24))) if pnl_std > 0 else 0

    print("I. T·ªîNG QUAN HI·ªÜU SU·∫§T:")
    print(f"  - L·ª£i nhu·∫≠n r√≤ng:      ${total_pnl_usd:,.2f} ({net_profit_percent:+.2f}%)")
    print(f"  - V·ªën cu·ªëi c√πng:        ${final_capital:,.2f} (t·ª´ ${INITIAL_CAPITAL:,.2f})")
    print(f"  - H·ªá s·ªë l·ª£i nhu·∫≠n:      {profit_factor:.2f} (M·ª•c ti√™u > 1.5)")

    print("\nII. TH·ªêNG K√ä GIAO D·ªäCH:")
    print(f"  - T·ªïng s·ªë l·ªánh:          {total_trades}")
    print(f"  - T·ª∑ l·ªá th·∫Øng:           {win_rate:.2f}% ({len(winning_trades)} th·∫Øng / {len(losing_trades)} thua)")
    print(f"  - L·ªùi/l·ªánh th·∫Øng TB:    ${avg_win_pnl:,.2f}")
    print(f"  - L·ªó/l·ªánh thua TB:      ${avg_loss_pnl:,.2f}")
    print(f"  - Th·ªùi gian gi·ªØ l·ªánh TB: {df['holding_hours'].mean():.2f} gi·ªù")

    print("\nIII. QU·∫¢N L√ù R·ª¶I RO:")
    print(f"  - S·ª•t gi·∫£m v·ªën t·ªëi ƒëa: {max_drawdown_percent:.2f}%")
    print(f"  - T·ª∑ l·ªá Sharpe (nƒÉm):   {sharpe_ratio:.2f} (M·ª•c ti√™u > 1.0)")

    # --- C·∫¢I TI·∫æN: Th√™m ph√¢n t√≠ch theo t·ª´ng c·∫∑p giao d·ªãch ---
    print("\nIV. PH√ÇN T√çCH THEO C·∫∂P GIAO D·ªäCH:")
    symbol_analysis = df.groupby('symbol')['pnl_usd'].agg(['sum', 'count', lambda x: (x > 0).sum() / len(x) * 100])
    symbol_analysis.columns = ['Total PnL ($)', 'Trade Count', 'Win Rate (%)']
    print(symbol_analysis.to_string(float_format="%.2f"))

    if debug_log:
        print("\nV. NH·∫¨T K√ù DEBUG (3 d√≤ng cu·ªëi):") # <-- THAY ƒê·ªîI: C·∫≠p nh·∫≠t ti√™u ƒë·ªÅ
        for line in debug_log:
            print(f"  {line}")

    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"{strategy_name}_{timestamp_str}.csv"
    csv_path = os.path.join(BACKTEST_RESULTS_DIR, csv_filename)
    df.to_csv(csv_path, index=False, float_format='%.4f')
    print(f"\n‚úÖ Chi ti·∫øt giao d·ªãch ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {csv_path}")
    print("="*80)

# ==============================================================================
# MAIN EXECUTION
# ==============================================================================
if __name__ == "__main__":
    print(" B·∫ÆT ƒê·∫¶U PHI√äN BACKTEST ƒêA CHI·∫æN L∆Ø·ª¢C ".center(80, "="))

    # C·∫ßn d·ªØ li·ªáu 1D cho logic ƒëa khung th·ªùi gian
    all_intervals_needed = list(set(INTERVALS_TO_TEST + ['1d']))
    all_data = load_all_historical_data(SYMBOLS_TO_TEST, all_intervals_needed, TOTAL_DAYS_TO_TEST)
    all_data_prepared = prepare_context_and_ai_data_for_backtest(all_data)

    if not any(any(not df.empty for df in sym_data.values()) for sym_data in all_data_prepared.values()):
        print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ backtest. Vui l√≤ng ki·ªÉm tra l·∫°i.")
    else:
        for name, config in STRATEGY_CONFIGS.items():
            history, final_cap, debug_messages = run_sniper_backtest(all_data_prepared, config)
            generate_backtest_report(name, config, history, final_cap, debug_messages)

    print(" K·∫æT TH√öC PHI√äN BACKTEST ".center(80, "="))
