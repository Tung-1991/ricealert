import os
import json
import requests
import feedparser
import hashlib
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv
import time
import re
from collections import Counter
import string

# Load environment
dotenv_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
load_dotenv(dotenv_path=dotenv_path)

# Config
VN_TZ = timezone(timedelta(hours=7))
BASE_DIR = "/root/ricealert/ricenews"
LOG_DIR = os.path.join(BASE_DIR, "lognew")
COOLDOWN_TRACKER = os.path.join(BASE_DIR, "cooldown_tracker.json")
DISCORD_WEBHOOK = os.getenv("DISCORD_NEWS_WEBHOOK")
os.makedirs(LOG_DIR, exist_ok=True)

# Watchlist coins from .env
WATCHED_COINS = set([s.replace("USDT", "").lower() for s in os.getenv("SYMBOLS", "").split(",")])
WATCHED_COINS.update(["btc", "eth"])

# Cooldown (ph√∫t)
COOLDOWN_LEVEL = {
    "CRITICAL": 60,
    "WARNING": 120,
    "ALERT": 240,
    "WATCHLIST": 360,
    "INFO": 480
}

KEYWORDS = {
    "CRITICAL": ["will list", "etf approval", "halving", "fomc", "interest rate hike", "cpi", "war", "approved", "regulatory approval"],
    "WARNING": ["delist", "unlock", "hack", "exploit", "sec", "lawsuit", "regulation", "maintenance", "downtime", "outage"],
    "ALERT": ["upgrade", "partnership", "margin", "futures launch", "mainnet launch", "testnet launch"],
    "WATCHLIST": ["airdrop", "voting", "ama", "token burn", "governance"]
}

RSS_SOURCES = {
    "CoinDesk": "https://www.coindesk.com/arc/outboundfeeds/rss",
    "Cointelegraph": "https://cointelegraph.com/rss"
}

STOPWORDS = {"the", "of", "in", "to", "on", "and", "for", "with", "will", "from", "this", "that", "a", "an", "is", "by", "as"}

MACRO_KEYWORDS = ["fomc", "interest rate", "cpi", "inflation", "sec", "lawsuit", "regulation", "fed", "market", "imf", "war"]

def detect_category_tag(title):
    title_l = title.lower()
    for coin in WATCHED_COINS:
        if coin in title_l:
            return coin
    if any(kw in title_l for kw in MACRO_KEYWORDS):
        return "macro"
    return "general"


def extract_trending_keywords(news_items, topk=3):
    words = []
    for item in news_items:
        tokens = item['title'].lower().translate(str.maketrans('', '', string.punctuation)).split()
        words += [w for w in tokens if w not in STOPWORDS and len(w) > 2]
    most_common = Counter(words).most_common(topk)
    return [kw for kw, _ in most_common]

def fetch_binance_announcements(limit=5):
    url = f"https://www.binance.com/bapi/composite/v1/public/cms/article/catalog/list/query?catalogId=48&pageSize={limit}&pageNo=1"
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(url, headers=headers, timeout=10)
        res.raise_for_status()
        data = res.json().get("data", {}).get("articles", [])
        return [
            {
                "id": f"binance_{item.get('code')}",
                "title": item.get("title"),
                "url": f"https://www.binance.com/en/support/announcement/{item.get('code')}",
                "source_name": "Binance",
                "published_at": datetime.now(VN_TZ).isoformat(),
                "tags": ["binance", "exchange"]
            } for item in data
        ]
    except Exception as e:
        print(f"[ERROR] Binance: {e}")
        return []

def fetch_rss(feed_url, tag):
    news = []
    try:
        feed = feedparser.parse(feed_url)
        for entry in feed.entries[:5]:
            uid = hashlib.md5(entry.link.encode()).hexdigest()[:12]
            news.append({
                "id": f"{tag}_{uid}",
                "title": entry.title,
                "url": entry.link,
                "source_name": tag,
                "published_at": entry.published,
                "tags": [tag.lower()]
            })
    except Exception as e:
        print(f"[ERROR] RSS {tag}: {e}")
    return news

def classify_news_level(title):
    title = title.lower()
    for level, keys in KEYWORDS.items():
        if any(key in title for key in keys):
            return level
    return "INFO"

def generate_suggestion_and_trend(title, source=None):
    title_l = title.lower()
    if re.search(r"\b(will|to)?\s*list\b", title_l) or "etf" in title_l:
        return "Tin t·ª©c v·ªÅ ni√™m y·∫øt m·ªõi ho·∫∑c s·∫£n ph·∫©m ETF ‚Äì ƒë√¢y th∆∞·ªùng l√† ch·∫•t x√∫c t√°c khi·∫øn gi√° bi·∫øn ƒë·ªông m·∫°nh.", "UPTREND"
    if "mainnet" in title_l or "launch" in title_l or "upgrade" in title_l:
        return "D·ª± √°n ƒëang tri·ªÉn khai c·∫≠p nh·∫≠t ho·∫∑c ra m·∫Øt s·∫£n ph·∫©m m·ªõi ‚Äì c√≥ th·ªÉ t·∫°o k·ª≥ v·ªçng tƒÉng tr∆∞·ªüng ng·∫Øn h·∫°n.", "UPTREND"
    if "hack" in title_l or "exploit" in title_l or "lawsuit" in title_l:
        return "Th√¥ng tin ti√™u c·ª±c: s·ª± c·ªë b·∫£o m·∫≠t ho·∫∑c ki·ªán t·ª•ng ‚Äì c√≥ kh·∫£ nƒÉng g√¢y √°p l·ª±c b√°n tr√™n th·ªã tr∆∞·ªùng.", "DOWNTREND"
    if "airdrop" in title_l:
        return "Th√¥ng b√°o v·ªÅ airdrop ‚Äì th∆∞·ªùng k√≠ch th√≠ch c·ªông ƒë·ªìng tham gia nh∆∞ng √≠t ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn gi√°.", "WATCH"
    if "governance" in title_l or "voting" in title_l:
        return "Tin t·ª©c li√™n quan ƒë·∫øn qu·∫£n tr·ªã, bi·ªÉu quy·∫øt ‚Äì ph·∫£n √°nh thay ƒë·ªïi chi·∫øn l∆∞·ª£c n·ªôi b·ªô c·ªßa d·ª± √°n.", "WATCH"
    if source == "Cointelegraph" and "vitalik" in title_l:
        return "Vitalik ƒë∆∞a ra nh·∫≠n ƒë·ªãnh m·ªõi ‚Äì c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn c·ªông ƒë·ªìng Ethereum.", "SIDEWAY"
    return "Kh√¥ng c√≥ n·ªôi dung mang t√≠nh ƒë·ªãnh h∆∞·ªõng r√µ r√†ng ‚Äì tin t·ª©c thi√™n v·ªÅ t·ªïng h·ª£p ho·∫∑c trung l·∫≠p.", "SIDEWAY"

# C√°c ph·∫ßn c√≤n l·∫°i c·ªßa file n√™n bao g·ªìm th√™m logic s·ª≠ d·ª•ng detect_category_tag v√† extract_trending_keywords trong c√°c b∆∞·ªõc x·ª≠ l√Ω v√† g·ª≠i d·ªØ li·ªáu.


def load_cooldown():
    if os.path.exists(COOLDOWN_TRACKER):
        with open(COOLDOWN_TRACKER, 'r') as f:
            return json.load(f)
    return {"per_id": {}, "last_sent": {}}

def save_cooldown(cooldown):
    with open(COOLDOWN_TRACKER, 'w') as f:
        json.dump(cooldown, f)

def save_news(news, signal=False):
    fname = f"{datetime.now(VN_TZ).strftime('%Y-%m-%d')}_{'news_signal' if signal else 'news_all'}.json"
    path = os.path.join(LOG_DIR, fname)
    try:
        with open(path, 'r', encoding='utf-8') as f:
            logs = json.load(f)
    except:
        logs = []


    exists = any(news['id'] == i.get('id') or news['title'] == i.get('title') for i in logs)
    if not exists:
        news['agent_tracking'] = 'open'
        logs.insert(0, news)
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(logs, f, indent=2, ensure_ascii=False)
        print(f"üÜï L∆∞u tin m·ªõi: {news['title']} ({news['level']})")
    else:
        print(f"‚è© B·ªè qua tin ƒë√£ t·ªìn t·∫°i: {news['title']}")

def send_discord_alert(message):
    if not DISCORD_WEBHOOK:
        print("[WARN] No DISCORD_WEBHOOK")
        return
    try:
        requests.post(DISCORD_WEBHOOK, json={"content": message}, timeout=10)
    except Exception as e:
        print(f"[ERROR] Discord send failed: {e}")

def summarize_trend(news_items):
    titles = [i['title'].lower() for i in news_items]
    suggestions = [i.get('suggestion', '') for i in news_items if i.get("suggestion")]
    if any("hack" in t for t in titles):
        return "M·ªôt s·ªë tin ti√™u c·ª±c li√™n quan t·ªõi b·∫£o m·∫≠t ho·∫∑c exploit", "DOWNTREND"
    if any("etf" in t or "list" in t for t in titles):
        return "Xu·∫•t hi·ªán tin v·ªÅ ETF ho·∫∑c ni√™m y·∫øt ‚Üí th·ªã tr∆∞·ªùng c√≥ th·ªÉ t√≠ch c·ª±c", "UPTREND"
    if suggestions:
        return suggestions[0], news_items[0].get("trend", "SIDEWAY")
    return "Kh√¥ng c√≥ tin t·ª©c n·ªïi b·∫≠t ho·∫∑c mang t√≠nh quy·∫øt ƒë·ªãnh", "SIDEWAY"

def send_daily_summary():
    fname = os.path.join(LOG_DIR, f"{datetime.now(VN_TZ).strftime('%Y-%m-%d')}_news_signal.json")
    if not os.path.exists(fname):
        return
    try:
        with open(fname, 'r', encoding='utf-8') as f:
            logs = json.load(f)
    except:
        return

    summary = {"CRITICAL": [], "WARNING": [], "ALERT": [], "WATCHLIST": []}
    for item in logs:
        if item.get("level") in summary:
            summary[item["level"].upper()].append(item)

    count_summary = {k: len(v) for k, v in summary.items()}
    all_items = sum(summary.values(), [])
    suggestion, trend = summarize_trend(all_items)

    msg = f"\nüìä **Daily News Summary - {datetime.now(VN_TZ).strftime('%d/%m')}**\n"
    for lvl, count in count_summary.items():
        if count:
            emoji = {"CRITICAL": "üî¥", "WARNING": "‚ö†Ô∏è", "ALERT": "üì£", "WATCHLIST": "üëÄ"}.get(lvl, "‚ÑπÔ∏è")
            msg += f"- {emoji} {lvl}: {count} tin\n"
    msg += f"\nüí° Suggestion: {suggestion}\nüìà Trend: **{trend}**\n\nüì∞ Chi ti·∫øt:\n"
    for lvl, items in summary.items():
        if not items:
            continue
        emoji = "üî¥" if lvl == "CRITICAL" else "‚ö†Ô∏è" if lvl == "WARNING" else "üì£"
        msg += f"\n{emoji} **{lvl}**\n"
        for item in items:
            msg += f"- [{item['source_name']}] [{item['title']}](<{item['url']}>) ‚Üí üîó\n"
    send_discord_alert(msg)

def main():
    all_news = fetch_binance_announcements()
    for tag, url in RSS_SOURCES.items():
        all_news += fetch_rss(url, tag)

    print(f"üìÖ Fetched {len(all_news)} news")
    cooldown = load_cooldown()
    now = datetime.now(VN_TZ).timestamp()
    cooldown_per_id = cooldown.get("per_id", {})
    last_sent = cooldown.get("last_sent", {})
    news_by_level = {level: [] for level in COOLDOWN_LEVEL}

    for news in all_news:
        level = classify_news_level(news['title'])
        news['level'] = level
        news["category_tag"] = detect_category_tag(news["title"])
        nid = news['id']

        if now - cooldown_per_id.get(nid, 0) < COOLDOWN_LEVEL[level] * 60:
            print(f"‚è≥ Cooldown: B·ªè qua {news['title']}")
            continue

        cooldown_per_id[nid] = now
        if level != "INFO":
            suggestion, trend = generate_suggestion_and_trend(news['title'], news.get("source_name"))
            news['suggestion'] = suggestion
            news['trend'] = trend
            save_news(news, signal=True)
        save_news(news)
        news_by_level[level].append(news)

    for level, items in news_by_level.items():
        if not items:
            continue
        if now - last_sent.get(level, 0) < COOLDOWN_LEVEL[level] * 60:
            continue

        last_sent[level] = now
        emoji = {
            "CRITICAL": "üî¥",
            "WARNING": "‚ö†Ô∏è",
            "ALERT": "üì£",
            "WATCHLIST": "üëÄ",
            "INFO": "‚ÑπÔ∏è"
        }[level]

        msg = f"{emoji} **{level} News**\n"
        for item in items:
            msg += f"[{item['source_name']}] [{item['title']}](<{item['url']}>) ‚Üí üîó\n"
        if level != "INFO":
            msg += f"\nüí° Suggestion: {summarize_trend(items)[0]}"
        send_discord_alert(msg)
        print(f"üì§ Sent {len(items)} {level} news")
        time.sleep(2)

    cooldown["per_id"] = cooldown_per_id
    cooldown["last_sent"] = last_sent
    save_cooldown(cooldown)

    if datetime.now(VN_TZ).hour in [8, 20]:
        send_daily_summary()

    print("‚úÖ Done")

if __name__ == "__main__":
    main()
