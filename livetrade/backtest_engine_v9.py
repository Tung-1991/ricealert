# /root/ricealert/backtest/backtest_engine_v9.py
# PHI√äN B·∫¢N 9.0 - M√î PH·ªéNG LIVE_TRADE v8.7+
# T√°c gi·∫£: Gemini & [T√™n c·ªßa b·∫°n]
# M·ª•c ti√™u: Backtest ch√≠nh x√°c c√°c logic m·ªõi nh·∫•t c·ªßa live_trade.py bao g·ªìm:
# - TACTICS_LAB: C√°c chi·∫øn thu·∫≠t ph·ª©c t·∫°p.
# - 4-ZONE MODEL: Ph√¢n t√≠ch v√πng th·ªã tr∆∞·ªùng.
# - RISK FENCING: SL v·ªõi S√ÄN (min) v√† TR·∫¶N (max) an to√†n.
# - ENSEMBLE AI: S·ª≠ d·ª•ng c·∫£ 3 model AI (LGBM, LSTM, Transformer).

import os
import sys
import pandas as pd
import joblib
import warnings
import json
from datetime import datetime
from typing import Dict, List, Tuple
import numpy as np

# --- Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n & Import ---
warnings.filterwarnings("ignore", category=UserWarning)
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

# Import c√°c th√†nh ph·∫ßn c·ªët l√µi t·ª´ h·ªá th·ªëng live
from livetrade.live_trade import (
    TACTICS_LAB, ZONE_BASED_POLICIES, RISK_RULES_CONFIG,
    get_mtf_adjustment_coefficient # S·∫Ω c·∫ßn import th√™m h√†m n√†y n·∫øu ch∆∞a c√≥
)
from indicator import calculate_indicators
from trade_advisor import get_advisor_decision, FULL_CONFIG as ADVISOR_BASE_CONFIG
from trainer import get_full_price_history, add_features # C·∫ßn 2 h√†m n√†y ƒë·ªÉ l·∫•y v√† x·ª≠ l√Ω d·ªØ li·ªáu
import tensorflow as tf
from keras.models import load_model

# --- C√°c h·∫±ng s·ªë Backtest ---
SYMBOLS_TO_TEST = ["ETHUSDT", "AVAXUSDT", "INJUSDT", "LINKUSDT", "SUIUSDT"] # R√∫t g·ªçn ƒë·ªÉ test nhanh h∆°n
INTERVALS_TO_TEST = ["1h", "4h"]
TOTAL_DAYS_TO_TEST = 90
INITIAL_CAPITAL = 10000.0
COMMISSION_RATE = 0.001 # Ph√≠ giao d·ªãch spot (mua + b√°n)
SEQUENCE_LENGTH = 60 # Ph·∫£i kh·ªõp v·ªõi model AI

# --- ƒê∆∞·ªùng d·∫´n ---
CACHE_DIR = os.path.join(current_dir, "data_cache")
DATA_DIR = os.path.join(project_root, "data")
BACKTEST_RESULTS_DIR = os.path.join(current_dir, "backtest_results")
os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(BACKTEST_RESULTS_DIR, exist_ok=True)

# Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u cache ch·ªâ b√°o, tr√°nh t√≠nh to√°n l·∫°i
indicator_results_cache = {}

def determine_market_zone_for_backtest(symbol: str, interval: str, candle: pd.Series) -> str:
    # H√†m n√†y l√† phi√™n b·∫£n ƒë∆°n gi·∫£n h√≥a c·ªßa h√†m trong live_trade
    # D·ª±a tr√™n d·ªØ li·ªáu c·ªßa m·ªôt c√¢y n·∫øn duy nh·∫•t
    adx = candle.get('adx', 20)
    bb_width = candle.get('bb_width', 0)
    
    if adx < 20 and bb_width < 0.05: # Gi·∫£ ƒë·ªãnh
        return "LEADING"
    if adx > 25:
        return "LAGGING"
    if candle.get('volume', 0) > candle.get('vol_ma20', 1) * 2:
        return "COINCIDENT"
    return "NOISE"

def prepare_ai_predictions_for_history(df: pd.DataFrame, symbol: str, interval: str) -> pd.DataFrame:
    """
    H√†m quan tr·ªçng: Ch·∫°y c√°c model AI hi·ªán t·∫°i tr√™n d·ªØ li·ªáu l·ªãch s·ª≠.
    """
    print(f"  -> Chu·∫©n b·ªã AI cho {symbol}-{interval}...")
    try:
        # T·∫£i t·∫•t c·∫£ model v√† scaler
        meta = json.load(open(os.path.join(DATA_DIR, f"meta_{symbol}_{interval}.json")))
        scaler = joblib.load(os.path.join(DATA_DIR, f"scaler_{symbol}_{interval}.pkl"))
        clf_lgbm = joblib.load(os.path.join(DATA_DIR, f"model_{symbol}_lgbm_clf_{interval}.pkl"))
        reg_lgbm = joblib.load(os.path.join(DATA_DIR, f"model_{symbol}_lgbm_reg_{interval}.pkl"))
        clf_lstm = load_model(os.path.join(DATA_DIR, f"model_{symbol}_lstm_clf_{interval}.keras"), compile=False)
        reg_lstm = load_model(os.path.join(DATA_DIR, f"model_{symbol}_lstm_reg_{interval}.keras"), compile=False)
        clf_trans = load_model(os.path.join(DATA_DIR, f"model_{symbol}_transformer_clf_{interval}.keras"), compile=False)
        reg_trans = load_model(os.path.join(DATA_DIR, f"model_{symbol}_transformer_clf_{interval}.keras"), compile=False)
    except Exception as e:
        print(f"     L·ªói: Kh√¥ng t√¨m th·∫•y ƒë·ªß b·ªô model cho {symbol}-{interval}. B·ªè qua AI. L·ªói: {e}")
        df['ai_prob_buy'], df['ai_prob_sell'], df['ai_pct'] = 50.0, 0.0, 0.0
        return df

    features_to_use = meta['features']
    df_scaled = df.copy()
    df_scaled[features_to_use] = scaler.transform(df[features_to_use])

    ai_results = []
    for i in range(len(df)):
        if i < SEQUENCE_LENGTH:
            ai_results.append({'prob_buy': 50.0, 'prob_sell': 0.0, 'pct': 0.0})
            continue

        # D·ªØ li·ªáu cho LGBM (d√≤ng cu·ªëi)
        latest_row = df[features_to_use].iloc[[i]]
        # D·ªØ li·ªáu cho LSTM/Transformer (chu·ªói 60 d√≤ng)
        sequence_data = df_scaled[features_to_use].iloc[i-SEQUENCE_LENGTH:i].values
        sequence_to_predict = sequence_data[np.newaxis, :, :]

        # D·ª± b√°o
        lgbm_prob = clf_lgbm.predict_proba(latest_row)[0]
        lgbm_reg = reg_lgbm.predict(latest_row)[0]
        lstm_prob = clf_lstm.predict(sequence_to_predict, verbose=0)[0]
        lstm_reg = reg_lstm.predict(sequence_to_predict, verbose=0)[0][0]
        trans_prob = clf_trans.predict(sequence_to_predict, verbose=0)[0]
        trans_reg = reg_trans.predict(sequence_to_predict, verbose=0)[0][0]

        # Ensemble
        prob_buy = (lgbm_prob[2] * 0.25) + (lstm_prob[2] * 0.35) + (trans_prob[2] * 0.40)
        prob_sell = (lgbm_prob[0] * 0.25) + (lstm_prob[0] * 0.35) + (trans_prob[0] * 0.40)
        pct = (lgbm_reg * 0.25) + (lstm_reg * 0.35) + (trans_reg * 0.40)
        
        ai_results.append({'prob_buy': prob_buy * 100, 'prob_sell': prob_sell * 100, 'pct': pct})

    ai_df = pd.DataFrame(ai_results, index=df.index)
    df['ai_prob_buy'] = ai_df['prob_buy']
    df['ai_prob_sell'] = ai_df['prob_sell']
    df['ai_pct'] = ai_df['pct']
    
    tf.keras.backend.clear_session()
    return df


def run_backtest_for_tactic(tactic_name: str, all_data: Dict):
    capital, trade_history = INITIAL_CAPITAL, []
    active_trade: Dict = {}
    tactic_cfg = TACTICS_LAB[tactic_name]

    # H·ª£p nh·∫•t t·∫•t c·∫£ c√°c index v√† s·∫Øp x·∫øp
    all_indices = [df.index for symbol_data in all_data.values() for df in symbol_data.values() if not df.empty]
    if not all_indices: return [], capital
    master_index = pd.DatetimeIndex(pd.concat([s.to_series() for s in all_indices]).unique()).sort_values()
    
    # Gi·ªõi h·∫°n ng√†y backtest
    end_date, start_date = master_index.max(), master_index.max() - pd.Timedelta(days=TOTAL_DAYS_TO_TEST)
    master_index = master_index[(master_index >= start_date) & (master_index <= end_date)]

    print(f"\n[Backtest] ƒêang ch·∫°y m√¥ ph·ªèng cho Tactic: {tactic_name}...")
    
    for timestamp in master_index:
        # 1. Qu·∫£n l√Ω l·ªánh ƒëang m·ªü
        if active_trade:
            symbol, interval = active_trade['symbol'], active_trade['interval']
            df_trade = all_data.get(symbol, {}).get(interval)
            if df_trade is not None and timestamp in df_trade.index:
                current_candle = df_trade.loc[timestamp]
                status, exit_price = (None, None)
                if current_candle['low'] <= active_trade['sl']:
                    status, exit_price = "SL", active_trade['sl']
                elif current_candle['high'] >= active_trade['tp']:
                    status, exit_price = "TP", active_trade['tp']
                
                if status:
                    pnl = (exit_price - active_trade['entry_price']) / active_trade['entry_price']
                    net_pnl_usd = (active_trade['amount_usd'] * pnl) - (active_trade['amount_usd'] * (1 + abs(pnl)) * COMMISSION_RATE)
                    capital += net_pnl_usd
                    active_trade.update({'exit_price': exit_price, 'exit_time': timestamp, 'pnl_usd': net_pnl_usd, 'status': status})
                    trade_history.append(active_trade)
                    active_trade = {} # ƒê√≥ng l·ªánh

        # 2. T√¨m c∆° h·ªôi m·ªõi (ch·ªâ khi kh√¥ng c√≥ l·ªánh n√†o ƒëang m·ªü)
        if not active_trade:
            for symbol in SYMBOLS_TO_TEST:
                for interval in INTERVALS_TO_TEST:
                    df = all_data.get(symbol, {}).get(interval)
                    if df is None or timestamp not in df.index: continue

                    candle = df.loc[timestamp]
                    
                    # M√¥ ph·ªèng vi·ªác t√≠nh to√°n ch·ªâ b√°o v√† zone
                    indicator_results_cache.setdefault(symbol, {}).setdefault(interval, {})
                    indicator_results_cache[symbol][interval] = calculate_indicators(df.loc[:timestamp].tail(300), symbol, interval)
                    market_zone = determine_market_zone_for_backtest(symbol, interval, candle)

                    if market_zone in tactic_cfg.get("OPTIMAL_ZONE", []):
                        # L·∫•y d·ªØ li·ªáu AI ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n tr∆∞·ªõc
                        ai_data = {"prob_buy": candle.get('ai_prob_buy', 50.0), "prob_sell": candle.get('ai_prob_sell', 0.0), "pct": candle.get('ai_pct', 0.0)}
                        # Gi·∫£ ƒë·ªãnh context trung l·∫≠p
                        context_data = {"market_trend": "NEUTRAL", "news_factor": 0.0}

                        decision = get_advisor_decision(symbol, interval, indicator_results_cache[symbol][interval], ADVISOR_BASE_CONFIG,
                                                      ai_data_override=ai_data, context_override=context_data,
                                                      weights_override=tactic_cfg.get("WEIGHTS"))
                        
                        if decision['final_score'] >= tactic_cfg.get("ENTRY_SCORE", 9.9):
                            entry_price = candle['close']
                            
                            # T√≠nh to√°n v·ªën theo Zone
                            capital_pct = ZONE_BASED_POLICIES.get(market_zone, {}).get("CAPITAL_PCT", 0.03)
                            amount_usd = capital * capital_pct

                            # T√≠nh to√°n SL/TP theo logic m·ªõi
                            risk_dist_from_atr = indicator_results_cache[symbol][interval].get('atr', 0) * tactic_cfg.get("ATR_SL_MULTIPLIER", 2.0)
                            min_risk_map = RISK_RULES_CONFIG.get("MIN_RISK_DIST_PERCENT_BY_TIMEFRAME", {})
                            max_risk_map = RISK_RULES_CONFIG.get("MAX_SL_PERCENT_BY_TIMEFRAME", {})
                            min_risk_pct = min_risk_map.get(interval, 0.02)
                            max_risk_pct = max_risk_map.get(interval, 0.10)
                            min_risk_dist = entry_price * min_risk_pct
                            max_risk_dist = entry_price * max_risk_pct
                            effective_risk_dist = max(risk_dist_from_atr, min_risk_dist)
                            final_risk_dist = min(effective_risk_dist, max_risk_dist)

                            sl = entry_price - final_risk_dist
                            tp = entry_price + (final_risk_dist * tactic_cfg.get("RR", 2.0))

                            active_trade = {
                                'symbol': symbol, 'interval': interval, 'entry_price': entry_price, 
                                'tp': tp, 'sl': sl, 'amount_usd': amount_usd, 'status': "open", 
                                'score': decision['final_score'], 'entry_time': timestamp, 'zone': market_zone
                            }
                            capital -= (amount_usd * COMMISSION_RATE) # Tr·ª´ ph√≠ mua
                            break # Ch·ªâ m·ªü 1 l·ªánh m·ªói l·∫ßn
                if active_trade:
                    break

    return trade_history, capital

def generate_report(tactic_name: str, trade_history: List[Dict], final_capital: float):
    print("\n\n" + "="*80)
    print(f"============== üìä B√ÅO C√ÅO BACKTEST CHO TACTIC: {tactic_name} üìä ==============")
    
    if not trade_history:
        print("Kh√¥ng c√≥ giao d·ªãch n√†o ƒë∆∞·ª£c th·ª±c hi·ªán.")
        return

    df = pd.DataFrame(trade_history)
    total_trades = len(df)
    winning_trades = df[df['pnl_usd'] > 0]
    win_rate = (len(winning_trades) / total_trades * 100) if total_trades > 0 else 0
    total_pnl_usd = final_capital - INITIAL_CAPITAL
    net_profit_percent = (total_pnl_usd / INITIAL_CAPITAL * 100)

    print(f"L·ª£i nhu·∫≠n r√≤ng:      ${total_pnl_usd:,.2f} ({net_profit_percent:+.2f}%)")
    print(f"V·ªën cu·ªëi c√πng:       ${final_capital:,.2f}")
    print(f"T·ªïng s·ªë l·ªánh:        {total_trades}")
    print(f"T·ª∑ l·ªá th·∫Øng:         {win_rate:.2f}%")
    
    timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    csv_filename = f"backtest_{tactic_name}_{TOTAL_DAYS_TO_TEST}d_{timestamp_str}.csv"
    csv_path = os.path.join(BACKTEST_RESULTS_DIR, csv_filename)
    df.to_csv(csv_path, index=False, float_format='%.4f')
    print(f"‚úÖ Chi ti·∫øt giao d·ªãch ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {csv_path}")
    print("="*80)

# ==============================================================================
# MAIN EXECUTION
# ==============================================================================
if __name__ == "__main__":
    print(" B·∫ÆT ƒê·∫¶U PHI√äN BACKTEST M√î PH·ªéNG LIVE_TRADE ".center(80, "="))

    # 1. T·∫£i v√† cache to√†n b·ªô d·ªØ li·ªáu gi√° l·ªãch s·ª≠
    all_data_historcial = {}
    for symbol in SYMBOLS_TO_TEST:
        all_data_historcial[symbol] = {}
        for interval in INTERVALS_TO_TEST:
            cache_file = os.path.join(CACHE_DIR, f"{symbol}-{interval}-{TOTAL_DAYS_TO_TEST}d.parquet")
            if os.path.exists(cache_file):
                df = pd.read_parquet(cache_file)
            else:
                limit = TOTAL_DAYS_TO_TEST * (24 if interval == '1h' else 6 if interval == '4h' else 1) + 300
                df = get_full_price_history(symbol, interval, limit, 1000)
                if not df.empty: df.to_parquet(cache_file)
            
            if not df.empty:
                print(f"ƒê√£ t·∫£i {len(df)} n·∫øn cho {symbol}-{interval}")
                df_with_features = add_features(df)
                all_data_historcial[symbol][interval] = prepare_ai_predictions_for_history(df_with_features, symbol, interval)
    
    # 2. Ch·∫°y backtest cho t·ª´ng Tactic trong TACTICS_LAB
    for tactic in TACTICS_LAB.keys():
        history, final_cap = run_backtest_for_tactic(tactic, all_data_historcial)
        generate_report(tactic, history, final_cap)

    print(" K·∫æT TH√öC PHI√äN BACKTEST ".center(80, "="))
